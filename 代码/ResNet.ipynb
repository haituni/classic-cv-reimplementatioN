{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2026-02-20T12:05:16.441105Z",
     "iopub.status.busy": "2026-02-20T12:05:16.440883Z",
     "iopub.status.idle": "2026-02-20T12:05:16.443080Z",
     "shell.execute_reply": "2026-02-20T12:05:16.442758Z",
     "shell.execute_reply.started": "2026-02-20T12:05:16.441090Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5027a9ea-6f72-4d77-b93a-b85e9e7d399c",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2026-02-20T12:05:16.443937Z",
     "iopub.status.busy": "2026-02-20T12:05:16.443747Z",
     "iopub.status.idle": "2026-02-20T12:05:20.701095Z",
     "shell.execute_reply": "2026-02-20T12:05:20.700699Z",
     "shell.execute_reply.started": "2026-02-20T12:05:16.443924Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.version_info(major=3, minor=12, micro=3, releaselevel='final', serial=0)\n",
      "matplotlib 3.10.1\n",
      "numpy 1.26.4\n",
      "pandas 2.2.3\n",
      "sklearn 1.6.1\n",
      "torch 2.7.0a0+7c8ec84dab.nv25.03\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "print(sys.version_info)\n",
    "for module in mpl, np, pd, sklearn, torch:\n",
    "    print(module.__name__, module.__version__)\n",
    "    \n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)\n",
    "\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee93e2c5-db3e-472b-802d-27b8f4a711b8",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2026-02-20T12:05:20.701969Z",
     "iopub.status.busy": "2026-02-20T12:05:20.701593Z",
     "iopub.status.idle": "2026-02-20T12:05:22.322734Z",
     "shell.execute_reply": "2026-02-20T12:05:22.322342Z",
     "shell.execute_reply.started": "2026-02-20T12:05:20.701954Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path(\".\")\n",
    "DATA_DIR1 =Path(\"competitions/cifar-10/\")\n",
    "train_lables_file = DATA_DIR / \"trainLabels.csv\"\n",
    "test_csv_file = DATA_DIR / \"sampleSubmission.csv\" #测试集模板csv文件\n",
    "train_folder = DATA_DIR1 / \"train\"\n",
    "test_folder = DATA_DIR1 / \"test\"\n",
    "\n",
    "#所有的类别\n",
    "class_names = [\n",
    "    'airplane',\n",
    "    'automobile',\n",
    "    'bird',\n",
    "    'cat',\n",
    "    'deer',\n",
    "    'dog',\n",
    "    'frog',\n",
    "    'horse',\n",
    "    'ship',\n",
    "    'truck',\n",
    "]\n",
    "\n",
    "def parse_csv_file(filepath, folder): # filepath:csv文件路径，folder:图片所在文件夹\n",
    "    \"\"\"Parses csv files into (filename(path), label) format\"\"\"\n",
    "    results = []\n",
    "    # 读取所有行\n",
    "    with open(filepath, 'r') as f:\n",
    "# lines = f.readlines()  为什么加[1:]，可以试这个\n",
    "        # 第一行不需要，因为第一行是标题\n",
    "        lines = f.readlines()[1:] \n",
    "    for line in lines:#依次去取每一行\n",
    "        image_id, label_str = line.strip('\\n').split(',') #图片id 和标签分离\n",
    "        image_full_path = folder / f\"{image_id}.png\"\n",
    "        results.append((image_full_path, label_str)) #得到对应图片的路径和分类\n",
    "    return results\n",
    "\n",
    "# 解析对应的文件夹\n",
    "train_labels_info = parse_csv_file(train_lables_file, train_folder)\n",
    "test_csv_info = parse_csv_file(test_csv_file, test_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "219e9629f892c7e1",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2026-02-20T12:05:22.323394Z",
     "iopub.status.busy": "2026-02-20T12:05:22.323210Z",
     "iopub.status.idle": "2026-02-20T12:05:22.381733Z",
     "shell.execute_reply": "2026-02-20T12:05:22.381196Z",
     "shell.execute_reply.started": "2026-02-20T12:05:22.323382Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            filepath       class\n",
      "0  competitions/cifar-10/train/1.png        frog\n",
      "1  competitions/cifar-10/train/2.png       truck\n",
      "2  competitions/cifar-10/train/3.png       truck\n",
      "3  competitions/cifar-10/train/4.png        deer\n",
      "4  competitions/cifar-10/train/5.png  automobile\n",
      "                                filepath       class\n",
      "0  competitions/cifar-10/train/45001.png       horse\n",
      "1  competitions/cifar-10/train/45002.png  automobile\n",
      "2  competitions/cifar-10/train/45003.png        deer\n",
      "3  competitions/cifar-10/train/45004.png  automobile\n",
      "4  competitions/cifar-10/train/45005.png    airplane\n",
      "                           filepath class\n",
      "0  competitions/cifar-10/test/1.png   cat\n",
      "1  competitions/cifar-10/test/2.png   cat\n",
      "2  competitions/cifar-10/test/3.png   cat\n",
      "3  competitions/cifar-10/test/4.png   cat\n",
      "4  competitions/cifar-10/test/5.png   cat\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# train_df = pd.DataFrame(train_labels_info)\n",
    "train_df = pd.DataFrame(train_labels_info[0:45000])\n",
    "valid_df = pd.DataFrame(train_labels_info[45000:])\n",
    "test_df = pd.DataFrame(test_csv_info)\n",
    "\n",
    "train_df.columns = ['filepath', 'class']\n",
    "valid_df.columns = ['filepath', 'class']\n",
    "test_df.columns = ['filepath', 'class']\n",
    "\n",
    "print(train_df.head())\n",
    "print(valid_df.head())\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "218bde88-8071-4fa0-a9ff-d8a8c2ab9a9a",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2026-02-20T12:05:22.382889Z",
     "iopub.status.busy": "2026-02-20T12:05:22.382740Z",
     "iopub.status.idle": "2026-02-20T12:05:24.056382Z",
     "shell.execute_reply": "2026-02-20T12:05:24.055998Z",
     "shell.execute_reply.started": "2026-02-20T12:05:22.382876Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "class Cifar10Dataset(Dataset):\n",
    "    df_map = {\n",
    "        \"train\": train_df,\n",
    "        \"eval\": valid_df,\n",
    "        \"test\": test_df\n",
    "    }\n",
    "    label_to_idx = {label: idx for idx, label in enumerate(class_names)}\n",
    "    idx_to_label = {idx: label for idx, label in enumerate(class_names)}\n",
    "    def __init__(self, mode, transform=None):\n",
    "        self.df = self.df_map.get(mode, None)\n",
    "        if self.df is None:\n",
    "            raise ValueError(\"mode should be one of train, val, test, but got {}\".format(mode))\n",
    "\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        img_path, label = self.df.iloc[index]\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        # # img 转换为 channel first\n",
    "        # img = img.transpose((2, 0, 1))\n",
    "        # transform\n",
    "        img = self.transform(img)\n",
    "        # label 转换为 idx\n",
    "        label = self.label_to_idx[label]\n",
    "        return img, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "IMAGE_SIZE = 224\n",
    "mean, std = [0.4650, 0.4553, 0.4213], [0.2272, 0.2235, 0.2208]\n",
    "\n",
    "transforms_train = transforms.Compose([\n",
    "        # resize\n",
    "        transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "        # random rotation 40\n",
    "        transforms.RandomRotation(15),\n",
    "        # horizaontal flip\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ])\n",
    "\n",
    "transforms_eval = transforms.Compose([\n",
    "        # resize\n",
    "        transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ])\n",
    "\n",
    "train_ds = Cifar10Dataset(\"train\", transforms_train)\n",
    "eval_ds = Cifar10Dataset(\"eval\", transforms_eval) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b1b34d2-d2af-445e-b6e4-292e628bf4ce",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2026-02-20T12:05:24.057213Z",
     "iopub.status.busy": "2026-02-20T12:05:24.056887Z",
     "iopub.status.idle": "2026-02-20T12:05:24.059603Z",
     "shell.execute_reply": "2026-02-20T12:05:24.059148Z",
     "shell.execute_reply.started": "2026-02-20T12:05:24.057198Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # 遍历train_ds得到每张图片，计算每个通道的均值和方差\n",
    "# def cal_mean_std(ds):\n",
    "#     mean = 0.\n",
    "#     std = 0.\n",
    "#     for img, _ in ds:\n",
    "#         mean += img.mean(dim=(1, 2))\n",
    "#         std += img.std(dim=(1, 2))\n",
    "#     mean /= len(ds)\n",
    "#     std /= len(ds)\n",
    "#     return mean, std\n",
    "\n",
    "# # 经过 normalize 后 均值为0，方差为1\n",
    "# print(cal_mean_std(train_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84d2a178-8eed-4cec-8efd-51b045db8883",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T12:05:24.060174Z",
     "iopub.status.busy": "2026-02-20T12:05:24.060054Z",
     "iopub.status.idle": "2026-02-20T12:05:24.063160Z",
     "shell.execute_reply": "2026-02-20T12:05:24.062679Z",
     "shell.execute_reply.started": "2026-02-20T12:05:24.060163Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=4)   \n",
    "eval_dl = DataLoader(eval_ds, batch_size=batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bba12ce-3250-43fe-bfcb-ca27ba4b5972",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2026-02-20T12:05:24.063819Z",
     "iopub.status.busy": "2026-02-20T12:05:24.063686Z",
     "iopub.status.idle": "2026-02-20T12:05:24.073359Z",
     "shell.execute_reply": "2026-02-20T12:05:24.072865Z",
     "shell.execute_reply.started": "2026-02-20T12:05:24.063808Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Residual(nn.Module):\n",
    "    \"\"\"浅层残差块（BasicBlock），无 bottleneck\"\"\"\n",
    "    def __init__(self, input_channels, output_channels, use_1x1conv=False, stride=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=input_channels,\n",
    "            out_channels=output_channels,\n",
    "            kernel_size=3,\n",
    "            stride=stride,\n",
    "            padding=1,\n",
    "            bias=False\n",
    "        )\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=output_channels,\n",
    "            out_channels=output_channels,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1,\n",
    "            bias=False\n",
    "        )\n",
    "        if use_1x1conv:\n",
    "            self.conv_sc = nn.Conv2d(\n",
    "                in_channels=input_channels,\n",
    "                out_channels=output_channels,\n",
    "                kernel_size=1,\n",
    "                stride=stride,\n",
    "                bias=False\n",
    "            )\n",
    "        else:\n",
    "            self.conv_sc = None\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(output_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(output_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        if self.conv_sc is not None:\n",
    "            identity = self.conv_sc(identity)\n",
    "        out += identity\n",
    "        return F.relu(out)\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels, num_blocks, first_block=False):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        for i in range(num_blocks):\n",
    "            if i == 0 and not first_block:\n",
    "                # 第一个 block 以外的 block，第一个单元需要降采样（stride=2）\n",
    "                layers.append(Residual(input_channels, output_channels, use_1x1conv=True, stride=2))\n",
    "            else:\n",
    "                # 其余单元 stride=1，通道不变\n",
    "                layers.append(Residual(output_channels, output_channels, use_1x1conv=False, stride=1))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block_nums=[2, 2, 2, 2], num_classes=1000):  # 默认 ResNet-18\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            block_nums: 每个 stage 的残差块数量，如 [2,2,2,2] -> ResNet-18\n",
    "            num_classes: 分类类别数（ImageNet 为 1000）\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        # 初始层：7x7 conv + maxpool\n",
    "        self.stem = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "\n",
    "        # 四个 stage\n",
    "        self.stage1 = ResidualBlock(64, 64, block_nums[0], first_block=True)   # conv2_x, H=56\n",
    "        self.stage2 = ResidualBlock(64, 128, block_nums[1])                    # conv3_x, H=28\n",
    "        self.stage3 = ResidualBlock(128, 256, block_nums[2])                   # conv4_x, H=14\n",
    "        self.stage4 = ResidualBlock(256, 512, block_nums[3])                   # conv5_x, H=7\n",
    "\n",
    "        # 分类头\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stem(x)\n",
    "        x = self.stage1(x)\n",
    "        x = self.stage2(x)\n",
    "        x = self.stage3(x)\n",
    "        x = self.stage4(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a31ac3f1-c62a-4478-9961-8c1c9ed3f3b4",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2026-02-20T12:05:24.074051Z",
     "iopub.status.busy": "2026-02-20T12:05:24.073883Z",
     "iopub.status.idle": "2026-02-20T12:05:24.199182Z",
     "shell.execute_reply": "2026-02-20T12:05:24.198801Z",
     "shell.execute_reply.started": "2026-02-20T12:05:24.074040Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stem.0: weight shape = torch.Size([64, 3, 7, 7])\n",
      "stage1.net.0.conv1: weight shape = torch.Size([64, 64, 3, 3])\n",
      "stage1.net.0.conv2: weight shape = torch.Size([64, 64, 3, 3])\n",
      "stage1.net.1.conv1: weight shape = torch.Size([64, 64, 3, 3])\n",
      "stage1.net.1.conv2: weight shape = torch.Size([64, 64, 3, 3])\n",
      "stage2.net.0.conv1: weight shape = torch.Size([128, 64, 3, 3])\n",
      "stage2.net.0.conv2: weight shape = torch.Size([128, 128, 3, 3])\n",
      "stage2.net.0.conv_sc: weight shape = torch.Size([128, 64, 1, 1])\n",
      "stage2.net.1.conv1: weight shape = torch.Size([128, 128, 3, 3])\n",
      "stage2.net.1.conv2: weight shape = torch.Size([128, 128, 3, 3])\n",
      "stage3.net.0.conv1: weight shape = torch.Size([256, 128, 3, 3])\n",
      "stage3.net.0.conv2: weight shape = torch.Size([256, 256, 3, 3])\n",
      "stage3.net.0.conv_sc: weight shape = torch.Size([256, 128, 1, 1])\n",
      "stage3.net.1.conv1: weight shape = torch.Size([256, 256, 3, 3])\n",
      "stage3.net.1.conv2: weight shape = torch.Size([256, 256, 3, 3])\n",
      "stage4.net.0.conv1: weight shape = torch.Size([512, 256, 3, 3])\n",
      "stage4.net.0.conv2: weight shape = torch.Size([512, 512, 3, 3])\n",
      "stage4.net.0.conv_sc: weight shape = torch.Size([512, 256, 1, 1])\n",
      "stage4.net.1.conv1: weight shape = torch.Size([512, 512, 3, 3])\n",
      "stage4.net.1.conv2: weight shape = torch.Size([512, 512, 3, 3])\n",
      "fc: weight shape = torch.Size([10, 512])\n"
     ]
    }
   ],
   "source": [
    "model = ResNet(num_classes=10)\n",
    "\n",
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, (nn.Conv2d, nn.Linear)):\n",
    "        print(f\"{name}: weight shape = {module.weight.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7abc5d49-b144-4dc9-8529-b0009be0aa24",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2026-02-20T12:07:01.875679Z",
     "iopub.status.busy": "2026-02-20T12:07:01.875400Z",
     "iopub.status.idle": "2026-02-20T12:07:01.996923Z",
     "shell.execute_reply": "2026-02-20T12:07:01.996431Z",
     "shell.execute_reply.started": "2026-02-20T12:07:01.875664Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters: 11179850\n"
     ]
    }
   ],
   "source": [
    "#模型总参数量\n",
    "\n",
    "model = ResNet(num_classes=len(class_names))\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total trainable parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f984a63-5806-4f27-a04a-282998376927",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T12:07:07.720967Z",
     "iopub.status.busy": "2026-02-20T12:07:07.720703Z",
     "iopub.status.idle": "2026-02-20T12:07:07.786416Z",
     "shell.execute_reply": "2026-02-20T12:07:07.786060Z",
     "shell.execute_reply.started": "2026-02-20T12:07:07.720953Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluating(model, dataloader, loss_fct):\n",
    "    loss_list = []\n",
    "    pred_list = []\n",
    "    label_list = []\n",
    "    for datas, labels in dataloader:\n",
    "        datas = datas.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # 前向计算\n",
    "        logits = model(datas)\n",
    "        loss = loss_fct(logits, labels)         # 验证集损失\n",
    "        loss_list.append(loss.item())\n",
    "        \n",
    "        preds = logits.argmax(axis=-1)    # 验证集预测\n",
    "        pred_list.extend(preds.cpu().numpy().tolist())\n",
    "        label_list.extend(labels.cpu().numpy().tolist())\n",
    "        \n",
    "    acc = accuracy_score(label_list, pred_list)\n",
    "    return np.mean(loss_list), acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd5b151e-1192-4a3b-9d0b-c73d750bede1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T12:07:09.716006Z",
     "iopub.status.busy": "2026-02-20T12:07:09.715554Z",
     "iopub.status.idle": "2026-02-20T12:07:09.719629Z",
     "shell.execute_reply": "2026-02-20T12:07:09.719233Z",
     "shell.execute_reply.started": "2026-02-20T12:07:09.715988Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SaveCheckpointsCallback:\n",
    "    def __init__(self, save_dir, save_step=5000, save_best_only=True):\n",
    "        self.save_dir = save_dir\n",
    "        self.save_step = save_step\n",
    "        self.save_best_only = save_best_only\n",
    "        self.best_metrics = -1\n",
    "        \n",
    "        # mkdir\n",
    "        if not os.path.exists(self.save_dir):\n",
    "            os.mkdir(self.save_dir)\n",
    "        \n",
    "    def __call__(self, step, state_dict, metric=None):\n",
    "        if step % self.save_step > 0:\n",
    "            return\n",
    "        \n",
    "        if self.save_best_only:\n",
    "            assert metric is not None\n",
    "            if metric >= self.best_metrics:\n",
    "                # save checkpoints\n",
    "                torch.save(state_dict, os.path.join(self.save_dir, \"best.ckpt\"))\n",
    "                # update best metrics\n",
    "                self.best_metrics = metric\n",
    "        else:\n",
    "            torch.save(state_dict, os.path.join(self.save_dir, f\"{step}.ckpt\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f10346e-349d-4e5c-a97a-1a000c2f299b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T12:07:11.155843Z",
     "iopub.status.busy": "2026-02-20T12:07:11.155568Z",
     "iopub.status.idle": "2026-02-20T12:07:11.158863Z",
     "shell.execute_reply": "2026-02-20T12:07:11.158515Z",
     "shell.execute_reply.started": "2026-02-20T12:07:11.155828Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EarlyStopCallback:\n",
    "    def __init__(self, patience=5, min_delta=0.01):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.best_metric = -1\n",
    "        self.counter = 0\n",
    "        \n",
    "    def __call__(self, metric):\n",
    "        if metric >= self.best_metric + self.min_delta:\n",
    "            # update best metric\n",
    "            self.best_metric = metric\n",
    "            # reset counter \n",
    "            self.counter = 0\n",
    "        else: \n",
    "            self.counter += 1\n",
    "            \n",
    "    @property\n",
    "    def early_stop(self):\n",
    "        return self.counter >= self.patience\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d610e64-7dae-4b2f-b96e-ab152d159660",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2026-02-20T12:07:12.837545Z",
     "iopub.status.busy": "2026-02-20T12:07:12.837135Z",
     "iopub.status.idle": "2026-02-20T12:20:31.426263Z",
     "shell.execute_reply": "2026-02-20T12:20:31.425812Z",
     "shell.execute_reply.started": "2026-02-20T12:07:12.837530Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 98.99it/s]\n",
      " 80%|████████  | 5632/7040 [13:17<03:19,  7.06it/s, epoch=15] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stop at epoch 16 / global_step 5632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "for i in tqdm(range(100)):\n",
    "    time.sleep(0.01)\n",
    "\n",
    "# 训练\n",
    "def training(\n",
    "    model, \n",
    "    train_loader, \n",
    "    val_loader, \n",
    "    epoch, \n",
    "    loss_fct, \n",
    "    optimizer, \n",
    "    save_ckpt_callback=None,\n",
    "    early_stop_callback=None,\n",
    "    eval_step=500,\n",
    "    ):\n",
    "    record_dict = {\n",
    "        \"train\": [],\n",
    "        \"val\": []\n",
    "    }\n",
    "    \n",
    "    global_step = 0\n",
    "    model.train()\n",
    "    with tqdm(total=epoch * len(train_loader)) as pbar:\n",
    "        for epoch_id in range(epoch):\n",
    "            # training\n",
    "            for datas, labels in train_loader:\n",
    "                datas = datas.to(device)\n",
    "                labels = labels.to(device)\n",
    "                # 梯度清空\n",
    "                optimizer.zero_grad()\n",
    "                # 模型前向计算\n",
    "                logits = model(datas)\n",
    "                # 计算损失\n",
    "                loss = loss_fct(logits, labels)\n",
    "                # 梯度回传\n",
    "                loss.backward()\n",
    "                # 调整优化器，包括学习率的变动等\n",
    "                optimizer.step()\n",
    "                preds = logits.argmax(axis=-1)\n",
    "            \n",
    "                acc = accuracy_score(labels.cpu().numpy(), preds.cpu().numpy())    \n",
    "                loss = loss.cpu().item()\n",
    "                # record\n",
    "                \n",
    "                record_dict[\"train\"].append({\n",
    "                    \"loss\": loss, \"acc\": acc, \"step\": global_step\n",
    "                })\n",
    "                \n",
    "                # evaluating\n",
    "                if global_step % eval_step == 0:\n",
    "                    model.eval()\n",
    "                    val_loss, val_acc = evaluating(model, val_loader, loss_fct)\n",
    "                    record_dict[\"val\"].append({\n",
    "                        \"loss\": val_loss, \"acc\": val_acc, \"step\": global_step\n",
    "                    })\n",
    "                    model.train()\n",
    "                    \n",
    "                \n",
    "                    # 保存模型权重 save model checkpoint\n",
    "                    if save_ckpt_callback is not None:\n",
    "                        save_ckpt_callback(global_step, model.state_dict(), metric=val_acc)\n",
    "\n",
    "                    # 早停 Early Stop\n",
    "                    if early_stop_callback is not None:\n",
    "                        early_stop_callback(val_acc)\n",
    "                        if early_stop_callback.early_stop:\n",
    "                            print(f\"Early stop at epoch {epoch_id} / global_step {global_step}\")\n",
    "                            return record_dict\n",
    "                    \n",
    "                # udate step\n",
    "                global_step += 1\n",
    "                pbar.update(1)\n",
    "                pbar.set_postfix({\"epoch\": epoch_id})\n",
    "        \n",
    "    return record_dict\n",
    "        \n",
    "\n",
    "epoch = 20\n",
    "\n",
    "model = ResNet(num_classes=10)\n",
    "\n",
    "# 1. 定义损失函数 采用交叉熵损失\n",
    "loss_fct = nn.CrossEntropyLoss()\n",
    "# 2. 定义优化器 \n",
    "optimizer = torch.optim.SGD(\n",
    "    model.parameters(),\n",
    "    lr=0.01,  \n",
    "    momentum=0.9,\n",
    "    weight_decay=5e-4     \n",
    ")\n",
    "\n",
    "# save best\n",
    "if not os.path.exists(\"checkpoints\"):\n",
    "    os.makedirs(\"checkpoints\")\n",
    "save_ckpt_callback = SaveCheckpointsCallback(\"checkpoints/ResNet\", save_step=len(train_dl), save_best_only=True)\n",
    "# early stop\n",
    "early_stop_callback = EarlyStopCallback(patience=5)\n",
    "\n",
    "model = model.to(device)\n",
    "record = training(\n",
    "    model, \n",
    "    train_dl, \n",
    "    eval_dl, \n",
    "    epoch, \n",
    "    loss_fct, \n",
    "    optimizer, \n",
    "    save_ckpt_callback=save_ckpt_callback,\n",
    "    early_stop_callback=early_stop_callback,\n",
    "    eval_step=len(train_dl)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d52606c-2851-45c4-b686-e0820b32c1cc",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.status.busy": "2026-02-20T12:05:24.305554Z",
     "iopub.status.idle": "2026-02-20T12:05:24.305712Z",
     "shell.execute_reply": "2026-02-20T12:05:24.305647Z",
     "shell.execute_reply.started": "2026-02-20T12:05:24.305640Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 损失是不一定在零到1之间的\n",
    "def plot_learning_curves(record_dict, sample_step=500):\n",
    "    # build DataFrame\n",
    "    train_df = pd.DataFrame(record_dict[\"train\"]).set_index(\"step\").iloc[::sample_step]\n",
    "    val_df = pd.DataFrame(record_dict[\"val\"]).set_index(\"step\")\n",
    "\n",
    "    # plot\n",
    "    fig_num = len(train_df.columns)\n",
    "    fig, axs = plt.subplots(1, fig_num, figsize=(5 * fig_num, 5))\n",
    "    for idx, item in enumerate(train_df.columns):    \n",
    "        axs[idx].plot(train_df.index, train_df[item], label=f\"train_{item}\")\n",
    "        axs[idx].plot(val_df.index, val_df[item], label=f\"val_{item}\")\n",
    "        axs[idx].grid()\n",
    "        axs[idx].legend()\n",
    "        # axs[idx].set_xticks(range(0, train_df.index[-1], 5000))\n",
    "        # axs[idx].set_xticklabels(map(lambda x: f\"{int(x/1000)}k\", range(0, train_df.index[-1], 5000)))\n",
    "        axs[idx].set_xlabel(\"step\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "plot_learning_curves(record, sample_step=100)  #横坐标是 steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ec2c4b-11c2-431f-95b1-e0f73ad54ee8",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2026-02-20T12:05:24.306108Z",
     "iopub.status.idle": "2026-02-20T12:05:24.306244Z",
     "shell.execute_reply": "2026-02-20T12:05:24.306183Z",
     "shell.execute_reply.started": "2026-02-20T12:05:24.306177Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 加载最佳模型并评估\n",
    "model.load_state_dict(torch.load(\"checkpoints/ResNet/best.ckpt\", map_location=\"cpu\"))\n",
    "\n",
    "model.eval()\n",
    "loss, acc = evaluating(model, eval_dl, loss_fct)\n",
    "print(f\"loss:     {loss:.4f}\\naccuracy: {acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
